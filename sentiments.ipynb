{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYpPq5+fhTO8gYago+8+D3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanupriya1125/sentiments/blob/main/sentiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwNYoDGHm9Jj",
        "outputId": "c7c5f2aa-c55d-48f2-dcee-599a2047862f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "metadata": {
        "id": "mkjMxMK9m_10"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir =\"/content/drive/MyDrive/tweet-sentiment/\""
      ],
      "metadata": {
        "id": "WgaMM6WPnLFD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(root_dir+\"train.csv\")"
      ],
      "metadata": {
        "id": "2e2IlRtYnL_p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPbTSBkfnOTz",
        "outputId": "e29be63a-a904-43da-9c2f-6ee52de086b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "textID           0\n",
              "text             1\n",
              "selected_text    1\n",
              "sentiment        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "g4bJa6kLnRI2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"sentiment\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqTvQKT7nTi-",
        "outputId": "a96d9517-9946-4843-f683-69d05a6cbd9c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'negative', 'positive'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"sentiment\"]] = df[[\"sentiment\"]].replace(to_replace =[\"neutral\"], \n",
        "                            value =0)\n",
        "df[[\"sentiment\"]] = df[[\"sentiment\"]].replace(to_replace =[\"negative\"], \n",
        "                            value =1)\n",
        "df[[\"sentiment\"]] = df[[\"sentiment\"]].replace(to_replace =[\"positive\"], \n",
        "                            value =2)"
      ],
      "metadata": {
        "id": "OTYd-xLPhIHS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df['text'],df['sentiment'],test_size=0.2, stratify=df['sentiment'],random_state=0)"
      ],
      "metadata": {
        "id": "a7jUCuTahJ7c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)"
      ],
      "metadata": {
        "id": "Fg6gh2awkJHJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 2000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(x_train)"
      ],
      "metadata": {
        "id": "ki1ghG0Xgxn9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = tok.texts_to_sequences(x_train)\n",
        "train_sequences = sequence.pad_sequences(train_sequences,maxlen=150)"
      ],
      "metadata": {
        "id": "FpW7z8ECjtzi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(x_test)\n",
        "test_sequences = sequence.pad_sequences(test_sequences,maxlen=150)"
      ],
      "metadata": {
        "id": "8T25c3wqj1Jm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers as L\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications import VGG16,VGG19\n",
        "\n",
        "\n",
        "def build_model(NUM_CLASSES):\n",
        "\n",
        "    input =  tf.keras.layers.Input(name='input',shape=[150])\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        " \n",
        "\n",
        "    \n",
        "    max_words = 2000\n",
        "    max_len = 200\n",
        "    text = L.Embedding(max_words,100,input_length=max_len)(input)\n",
        "    text = L.BatchNormalization()(text)\n",
        "    text = L.LSTM(500,activation=\"relu\")(text)\n",
        "\n",
        "\n",
        "    \n",
        "    # text = L.LSTM(128,return_sequences = True,activation=\"relu\")(text)\n",
        "    # text = L.Flatten()(text)\n",
        "    text = L.Dense(units=512,activation=\"relu\")(text)\n",
        "    \n",
        "    \n",
        "    \n",
        "    outputs = L.Dense(NUM_CLASSES, activation=\"softmax\", )(text)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Compile\n",
        "    model = Model(inputs=input, outputs=outputs, name=\"SentimentClassifier\")\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model(NUM_CLASSES=3)"
      ],
      "metadata": {
        "id": "S6puzOw_n7JE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(  loss='categorical_crossentropy',\n",
        "  optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001\n",
        "),\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zPKWBwC1iPGs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfZPwB7GoKkD",
        "outputId": "eca735b4-7d2a-48ef-9f72-4a804cc1b807"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"SentimentClassifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 100)          200000    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 150, 100)         400       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 500)               1202000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               256512    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,660,451\n",
            "Trainable params: 1,660,251\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "         train_sequences, y_train, \n",
        "          validation_data=(test_sequences,y_test),\n",
        "          epochs=15,\n",
        "          batch_size=128,\n",
        "          #  callbacks=callbacks\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni71sTfaoPXV",
        "outputId": "75486800-447b-4083-a6a3-07467ad70b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            " 57/172 [========>.....................] - ETA: 6:03 - loss: 1.0778 - accuracy: 0.4183"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.argmax(y_test,axis=1)\n",
        "y_true"
      ],
      "metadata": {
        "id": "eelWITGXoUq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_sequences,batch_size = 32,verbose=1)\n",
        "y_pred_1 = np.argmax(y_pred,axis=1)\n",
        "y_pred_1"
      ],
      "metadata": {
        "id": "w8MzTaiFoXY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "IiGMsuQ2oaNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat = confusion_matrix(y_true, y_pred_1).astype('float')\n",
        "mat = (mat/mat.astype(np.float).sum(axis=0))*100"
      ],
      "metadata": {
        "id": "F0fpHUQZod5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cm = pd.DataFrame(mat, range(3), range(3))\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.set(font_scale=1) # for label size\n",
        "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 12},fmt='.1f') # font size\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z7qubarJogMq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}